<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Nova`s Wiki</title>
  
  
  <link href="/wiki/atom.xml" rel="self"/>
  
  <link href="http://wiki.quartz.ren/"/>
  <updated>2019-03-11T15:56:09.564Z</updated>
  <id>http://wiki.quartz.ren/</id>
  
  <author>
    <name>Nova</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>函数式接口-FunctionalInterface</title>
    <link href="http://wiki.quartz.ren/wiki/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/Java/%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3-FunctionalInterface/"/>
    <id>http://wiki.quartz.ren/wiki/程序语言/Java/函数式接口-FunctionalInterface/</id>
    <published>2019-03-09T03:55:57.000Z</published>
    <updated>2019-03-11T15:56:09.564Z</updated>
    
    <content type="html"><![CDATA[<h3 id="什么是函数式接口"><a href="#什么是函数式接口" class="headerlink" title="什么是函数式接口"></a>什么是函数式接口</h3><p>其实之前在讲Lambda表达式的时候提到过，所谓的函数式接口，当然首先是一个接口，然后就是在这个接口里面只能有一个抽象方法。</p><p>这种类型的接口也称为SAM接口，即Single Abstract Method interfaces。</p><p>###　用途<br>它们主要用在Lambda表达式和方法引用（实际上也可认为是Lambda表达式）上</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">GreetingService</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sayMessage</span><span class="params">(String message)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么就可以使用Lambda表达式来表示该接口的一个实现(注：JAVA 8 之前一般是用匿名类实现的)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GreetingService greetService1 = message -&gt; System.out.println(<span class="string">"Hello "</span> + message);</span><br></pre></td></tr></table></figure><h3 id="关于-FunctionalInterface注解"><a href="#关于-FunctionalInterface注解" class="headerlink" title="关于@FunctionalInterface注解"></a>关于@FunctionalInterface注解</h3><p>Java 8为函数式接口引入了一个新注解@FunctionalInterface，主要用于编译级错误检查，加上该注解，当你写的接口不符合函数式接口定义的时候，编译器会报错。</p><p>提醒：加不加@FunctionalInterface对于接口是不是函数式接口没有影响，该注解知识提醒编译器去检查该接口是否仅包含一个抽象方法</p><h3 id="函数式接口里允许定义默认方法"><a href="#函数式接口里允许定义默认方法" class="headerlink" title="函数式接口里允许定义默认方法"></a>函数式接口里允许定义默认方法</h3><p>函数式接口里是可以包含默认方法，因为默认方法不是抽象方法，其有一个默认实现，所以是符合函数式接口的定义的；</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FunctionalInterface</span></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">GreetingService</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">sayMessage</span><span class="params">(String message)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">doSomeMoreWork1</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// Method body</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">doSomeMoreWork2</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// Method body</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="JDK中的函数式接口举例"><a href="#JDK中的函数式接口举例" class="headerlink" title="JDK中的函数式接口举例"></a>JDK中的函数式接口举例</h3><p>java.lang.Runnable,<br>java.awt.event.ActionListener,<br>java.util.Comparator,<br>java.util.concurrent.Callable<br>java.util.function包下的接口，如Consumer、Predicate、Supplier等</p><p><a href="https://www.cnblogs.com/runningTurtle/p/7092632.html" rel="external nofollow noopener noreferrer" target="_blank">Java 8 函数式接口 - Functional Interface</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;什么是函数式接口&quot;&gt;&lt;a href=&quot;#什么是函数式接口&quot; class=&quot;headerlink&quot; title=&quot;什么是函数式接口&quot;&gt;&lt;/a&gt;什么是函数式接口&lt;/h3&gt;&lt;p&gt;其实之前在讲Lambda表达式的时候提到过，所谓的函数式接口，当然首先是一个接口，然后就是在
      
    
    </summary>
    
      <category term="程序语言" scheme="http://wiki.quartz.ren/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"/>
    
      <category term="Java" scheme="http://wiki.quartz.ren/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/Java/"/>
    
    
      <category term="Java" scheme="http://wiki.quartz.ren/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Netty的NioEventLoop</title>
    <link href="http://wiki.quartz.ren/wiki/MicroService/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/Netty/Netty%E7%9A%84NioEventLoop/"/>
    <id>http://wiki.quartz.ren/wiki/MicroService/技术框架/Netty/Netty的NioEventLoop/</id>
    <published>2019-03-08T17:13:34.000Z</published>
    <updated>2019-03-16T10:50:43.877Z</updated>
    
    <content type="html"><![CDATA[<h2 id="NioEventLoop"><a href="#NioEventLoop" class="headerlink" title="NioEventLoop"></a>NioEventLoop</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public final class NioEventLoop extends SingleThreadEventLoop &#123;</span><br><span class="line">    private Selector selector;</span><br><span class="line">    private Selector unwrappedSelector;</span><br><span class="line">    private SelectedSelectionKeySet selectedKeys;</span><br><span class="line"></span><br><span class="line">    private final SelectorProvider provider;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Boolean that controls determines if a blocked Selector.select should</span><br><span class="line">     * break out of its selection process. In our case we use a timeout for</span><br><span class="line">     * the select method and the select method will block for that time unless</span><br><span class="line">     * waken up.</span><br><span class="line">     */</span><br><span class="line">    private final AtomicBoolean wakenUp = new AtomicBoolean();</span><br><span class="line"></span><br><span class="line">    private final SelectStrategy selectStrategy;</span><br><span class="line"></span><br><span class="line">    private volatile int ioRatio = 50;</span><br><span class="line">    private int cancelledKeys;</span><br><span class="line">    private boolean needsToSelectAgain;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>NioEventLoop 是Netty的核心类。</p><p>NioEventLoop 的首要职责就是为注册在它上的 channels 服务，发现这些 channels 上发生的新连接事件、读写等 I/O 事件，然后将事件转交 channel 流水线处理。</p><p><a href="https://www.jianshu.com/p/064a188b1803" rel="external nofollow noopener noreferrer" target="_blank">NioEventLoop 的职责</a></p><h3 id="发现策略"><a href="#发现策略" class="headerlink" title="发现策略"></a>发现策略</h3><p>SelectStrategy selectStrategy<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">final class DefaultSelectStrategy implements SelectStrategy &#123;</span><br><span class="line">    static final SelectStrategy INSTANCE = new DefaultSelectStrategy();</span><br><span class="line">    private DefaultSelectStrategy() &#123; &#125;</span><br><span class="line">    @Override</span><br><span class="line">    public int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception &#123;</span><br><span class="line">        return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;NioEventLoop&quot;&gt;&lt;a href=&quot;#NioEventLoop&quot; class=&quot;headerlink&quot; title=&quot;NioEventLoop&quot;&gt;&lt;/a&gt;NioEventLoop&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="MicroService" scheme="http://wiki.quartz.ren/categories/MicroService/"/>
    
      <category term="技术框架" scheme="http://wiki.quartz.ren/categories/MicroService/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/"/>
    
      <category term="Netty" scheme="http://wiki.quartz.ren/categories/MicroService/%E6%8A%80%E6%9C%AF%E6%A1%86%E6%9E%B6/Netty/"/>
    
    
      <category term="Netty" scheme="http://wiki.quartz.ren/tags/Netty/"/>
    
  </entry>
  
  <entry>
    <title>FastText</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/NLP/FastText/"/>
    <id>http://wiki.quartz.ren/wiki/机器学习/NLP/FastText/</id>
    <published>2019-03-06T14:55:57.000Z</published>
    <updated>2019-03-06T16:57:26.947Z</updated>
    
    <content type="html"><![CDATA[<h3 id="ngram"><a href="#ngram" class="headerlink" title="ngram"></a>ngram</h3><p>fastText可以在词向量的训练和句子分类上取得非常好的表现，尤其表现在对罕见词进行字符粒度上的处理。</p><p>每个单词除了单词本身外还被表示为多个字符级别的n-grams(有时候也称为N元模子)</p><p>例如对于单词  <strong>matter</strong>.</p><p>当n=3时， fasttext对该词对字符ngram就表示为  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;ma, mat, att, tte, ter, er&gt;</span><br></pre></td></tr></table></figure><p>其中&lt; 和 &gt; 是作为边界符号被添加，来将一个单词的ngrams与单词本身区分开来。</p><blockquote><p>再举一个例子，如果单词mat属于我们的词汇表，则会被表示为<mat> . 这么做刚好让一些短词以其他词的ngram出现，有助于更好的学习到这些短词的含义。</mat></p></blockquote><p>从本质上讲，这可以帮助你捕捉后缀/前缀的含义。</p><h3 id="minn-maxn"><a href="#minn-maxn" class="headerlink" title="minn,maxn"></a>minn,maxn</h3><p>可以通过-minn和-maxn这两个参数来控制ngrams的长度，这两个标志分别决定了<strong>ngrams的最小和最大字符数</strong>，也即控制了ngrams的范围。</p><p>这个模型被认为是一个词袋模型，因为除了用于选择n-gram的滑动窗口外,它并没有考虑对单词的内部结构进行特征选择。</p><blockquote><p>它只要求字符落在窗口以内，但并不关心ngrams的顺序。</p></blockquote><p>你可以将这两个值都设为0来完全关闭n-gram. 也就是不产生n-gram符号，单纯用单词作为输入.</p><p>当您的模型中的“单词”不是特定语音的单词时或者说字符级别的n-gram没有意义的时候，这会变得很有用。最常见的例子是当您将id作为您的单词输入。</p><p>在模型更新期间，fastText会学习到每个ngram以及整个单词符号的权重。</p><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><p>虽然fastText的训练是多线程的，但是读取数据却是通过单线程来完成。而文本解析和分词则在读取输入数据时就被完成了。让我们来看看具体是怎么做到的:</p><p>FastText通过-input参数获取一个文件句柄用于输入数据。FastText不支持从stdin读取数据，它初始化两个向量word2int_和words_来跟踪输入信息。</p><p>word2int_是一个字符串到数值的映射集，索引键是单词字符串，根据字符串哈希值可以得到一个数值作为它的值，同时这个数值恰好就对应到了words_数组(std:::vector)的索引。</p><p>words_数组在读取输入时根据单词出现的顺序递增创建索引，每个索引对应的值是一个结构体entry，这个entry封装了单词的所有信息。条目包含以下信息:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct entry &#123;</span><br><span class="line">std::string word;</span><br><span class="line">int64_t count;</span><br><span class="line">entry_type type;</span><br><span class="line">std::vector&lt;int32_t&gt; subwords;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><a href="https://baijiahao.baidu.com/s?id=1606667200878009384&amp;wfr=spider&amp;for=pc" rel="external nofollow noopener noreferrer" target="_blank">https://baijiahao.baidu.com/s?id=1606667200878009384&amp;wfr=spider&amp;for=pc</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;ngram&quot;&gt;&lt;a href=&quot;#ngram&quot; class=&quot;headerlink&quot; title=&quot;ngram&quot;&gt;&lt;/a&gt;ngram&lt;/h3&gt;&lt;p&gt;fastText可以在词向量的训练和句子分类上取得非常好的表现，尤其表现在对罕见词进行字符粒度上的处理。&lt;/p&gt;
&lt;
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wiki.quartz.ren/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="NLP" scheme="http://wiki.quartz.ren/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/NLP/"/>
    
    
      <category term="MchineLearning" scheme="http://wiki.quartz.ren/tags/MchineLearning/"/>
    
  </entry>
  
  <entry>
    <title>简单线性回归实现</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9/002.%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0/"/>
    <id>http://wiki.quartz.ren/wiki/机器学习/机器学习100天/002.简单线性回归实现/</id>
    <published>2019-03-03T15:55:57.000Z</published>
    <updated>2019-03-03T09:48:36.771Z</updated>
    
    <content type="html"><![CDATA[<h3 id="第一步：数据预处理"><a href="#第一步：数据预处理" class="headerlink" title="第一步：数据预处理"></a>第一步：数据预处理</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">dataset = pd.read_csv(<span class="string">'studentscores.csv'</span>)</span><br><span class="line">X = dataset.iloc[ : ,   : <span class="number">1</span> ].values</span><br><span class="line">Y = dataset.iloc[ : , <span class="number">1</span> ].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = <span class="number">1</span>/<span class="number">4</span>, random_state = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="第二步：训练集使用简单线性回归模型来训练"><a href="#第二步：训练集使用简单线性回归模型来训练" class="headerlink" title="第二步：训练集使用简单线性回归模型来训练"></a>第二步：训练集使用简单线性回归模型来训练</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor = regressor.fit(X_train, Y_train)</span><br></pre></td></tr></table></figure><h3 id="第三步：预测结果"><a href="#第三步：预测结果" class="headerlink" title="第三步：预测结果"></a>第三步：预测结果</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y_pred = regressor.predict(X_test)</span><br></pre></td></tr></table></figure><h3 id="第四步：可视化"><a href="#第四步：可视化" class="headerlink" title="第四步：可视化"></a>第四步：可视化</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = pd.read_csv(<span class="string">'~/Documents/100-Days-Of-ML-Code/datasets/studentscores.csv'</span>)</span><br><span class="line">X = dataset.iloc[ : ,   : <span class="number">1</span> ].values</span><br><span class="line">Y = dataset.iloc[ : , <span class="number">1</span> ].values</span><br><span class="line"></span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = <span class="number">1</span>/<span class="number">4</span>, random_state = <span class="number">0</span>) </span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor = regressor.fit(X_train, Y_train)</span><br><span class="line"></span><br><span class="line">Y_pred = regressor.predict(X_test)</span><br><span class="line"></span><br><span class="line">plt.scatter(X_train , Y_train, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_train , regressor.predict(X_train), color =<span class="string">'blue'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.scatter(X_test , Y_test, color = <span class="string">'red'</span>)</span><br><span class="line">plt.plot(X_test , regressor.predict(X_test), color =<span class="string">'blue'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;第一步：数据预处理&quot;&gt;&lt;a href=&quot;#第一步：数据预处理&quot; class=&quot;headerlink&quot; title=&quot;第一步：数据预处理&quot;&gt;&lt;/a&gt;第一步：数据预处理&lt;/h3&gt;&lt;figure class=&quot;highlight py&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td c
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wiki.quartz.ren/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习100天" scheme="http://wiki.quartz.ren/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9/"/>
    
    
      <category term="MchineLearning" scheme="http://wiki.quartz.ren/tags/MchineLearning/"/>
    
  </entry>
  
  <entry>
    <title>数据预处理</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9/001.%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <id>http://wiki.quartz.ren/wiki/机器学习/机器学习100天/001.数据预处理/</id>
    <published>2019-02-28T15:55:57.000Z</published>
    <updated>2019-02-28T16:44:14.158Z</updated>
    
    <content type="html"><![CDATA[<h3 id="导入需要的包"><a href="#导入需要的包" class="headerlink" title="导入需要的包"></a>导入需要的包</h3><p>numpy, pandas</p><h3 id="导入数据集"><a href="#导入数据集" class="headerlink" title="导入数据集"></a>导入数据集</h3><p>数据集通常为.csv格式.</p><p>使用Pandas的read_csv方法读取本地csv文件为一个数据帧。</p><p>然后，从数据帧中制作自变量和因变量的矩阵和向量。</p><h3 id="处理丢失数据集"><a href="#处理丢失数据集" class="headerlink" title="处理丢失数据集"></a>处理丢失数据集</h3><p>大多数据集是不完整的，为了不降低机器学习模型的性能，需要处理数据。</p><p>可以使用整列的平均值或中间值替换丢失的数据。我们使用sklean.preprocssing库中的Imputer类完成这项任务。</p><h3 id="解析分类数据"><a href="#解析分类数据" class="headerlink" title="解析分类数据"></a>解析分类数据</h3><p>分类数据指的是含有标签值而不是数字值的变量。取值范围通常是固定的。例如”Yes”和“No”.不能用于模型的数学计算，所以需要解析成数字。</p><p>为了实现这一功能，我们从sklearn.preprocesing库中导入LabelEncoder类。</p><h3 id="拆分数据集为测试集合和训练集合"><a href="#拆分数据集为测试集合和训练集合" class="headerlink" title="拆分数据集为测试集合和训练集合"></a>拆分数据集为测试集合和训练集合</h3><p>一般比例为80:20</p><p>导入sklearn.crossvalidation库中的train_test_split()方法。</p><h3 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h3><p>大部分模型算法使用两点间的欧式距离表示，但此特征在幅度、单位和范围姿态问题上变化很大。</p><p>在距离计算中，高幅度的特征比低幅度特征权重更大。可用特征标准化或Z值归一化解决。</p><p>导入sklearn.preprocessing库中的StandardScalar类。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Day 1: Data Prepocessing</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 1: Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 2: Importing dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'../datasets/Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[ : , :<span class="number">-1</span>].values</span><br><span class="line">Y = dataset.iloc[ : , <span class="number">3</span>].values</span><br><span class="line">print(<span class="string">"Step 2: Importing dataset"</span>)</span><br><span class="line">print(<span class="string">"X"</span>)</span><br><span class="line">print(X)</span><br><span class="line">print(<span class="string">"Y"</span>)</span><br><span class="line">print(Y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 3: Handling the missing data</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line">imputer = Imputer(missing_values = <span class="string">"NaN"</span>, strategy = <span class="string">"mean"</span>, axis = <span class="number">0</span>)</span><br><span class="line">imputer = imputer.fit(X[ : , <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">X[ : , <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X[ : , <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">print(<span class="string">"---------------------"</span>)</span><br><span class="line">print(<span class="string">"Step 3: Handling the missing data"</span>)</span><br><span class="line">print(<span class="string">"step2"</span>)</span><br><span class="line">print(<span class="string">"X"</span>)</span><br><span class="line">print(X)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 4: Encoding categorical data</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[ : , <span class="number">0</span>] = labelencoder_X.fit_transform(X[ : , <span class="number">0</span>])</span><br><span class="line"><span class="comment">#Creating a dummy variable</span></span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features = [<span class="number">0</span>])</span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br><span class="line">labelencoder_Y = LabelEncoder()</span><br><span class="line">Y =  labelencoder_Y.fit_transform(Y)</span><br><span class="line">print(<span class="string">"---------------------"</span>)</span><br><span class="line">print(<span class="string">"Step 4: Encoding categorical data"</span>)</span><br><span class="line">print(<span class="string">"X"</span>)</span><br><span class="line">print(X)</span><br><span class="line">print(<span class="string">"Y"</span>)</span><br><span class="line">print(Y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 5: Splitting the datasets into training sets and Test sets</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line">print(<span class="string">"---------------------"</span>)</span><br><span class="line">print(<span class="string">"Step 5: Splitting the datasets into training sets and Test sets"</span>)</span><br><span class="line">print(<span class="string">"X_train"</span>)</span><br><span class="line">print(X_train)</span><br><span class="line">print(<span class="string">"X_test"</span>)</span><br><span class="line">print(X_test)</span><br><span class="line">print(<span class="string">"Y_train"</span>)</span><br><span class="line">print(Y_train)</span><br><span class="line">print(<span class="string">"Y_test"</span>)</span><br><span class="line">print(Y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Step 6: Feature Scaling</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train = sc_X.fit_transform(X_train)</span><br><span class="line">X_test = sc_X.transform(X_test)</span><br><span class="line">print(<span class="string">"---------------------"</span>)</span><br><span class="line">print(<span class="string">"Step 6: Feature Scaling"</span>)</span><br><span class="line">print(<span class="string">"X_train"</span>)</span><br><span class="line">print(X_train)</span><br><span class="line">print(<span class="string">"X_test"</span>)</span><br><span class="line">print(X_test)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;导入需要的包&quot;&gt;&lt;a href=&quot;#导入需要的包&quot; class=&quot;headerlink&quot; title=&quot;导入需要的包&quot;&gt;&lt;/a&gt;导入需要的包&lt;/h3&gt;&lt;p&gt;numpy, pandas&lt;/p&gt;
&lt;h3 id=&quot;导入数据集&quot;&gt;&lt;a href=&quot;#导入数据集&quot; clas
      
    
    </summary>
    
      <category term="机器学习" scheme="http://wiki.quartz.ren/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="机器学习100天" scheme="http://wiki.quartz.ren/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0100%E5%A4%A9/"/>
    
    
      <category term="MchineLearning" scheme="http://wiki.quartz.ren/tags/MchineLearning/"/>
    
  </entry>
  
  <entry>
    <title>在看的书和文章</title>
    <link href="http://wiki.quartz.ren/wiki/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/%E5%9C%A8%E7%9C%8B%E7%9A%84%E4%B9%A6%E5%92%8C%E6%96%87%E7%AB%A0/"/>
    <id>http://wiki.quartz.ren/wiki/生活学习/在看的书和文章/</id>
    <published>2019-02-24T01:56:24.000Z</published>
    <updated>2019-02-24T01:28:15.668Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://www.quartz.ren" target="_blank" rel="noopener">个人博客</a></p><p><a href="https://www.kancloud.cn/thinkphp/docker_practice/30894" rel="external nofollow noopener noreferrer" target="_blank">Docker — 从入门到实践</a></p><p><a href="https://www.kancloud.cn/digest/java-designer-patten/163173" rel="external nofollow noopener noreferrer" target="_blank">学习java设计模式</a></p><p><a href="https://www.kancloud.cn/sstd521/design/193489" rel="external nofollow noopener noreferrer" target="_blank">设计模式之禅（第2版）</a></p><p><a href="https://www.kancloud.cn/kancloud/hadoop-notebook/45557" rel="external nofollow noopener noreferrer" target="_blank">hadoop-notebook</a></p><p><a href="https://gitee.com/quantumcs/Note/wikis/pages" rel="external nofollow noopener noreferrer" target="_blank">gitee-pages</a></p><h2 id="有趣的文章"><a href="#有趣的文章" class="headerlink" title="有趣的文章"></a>有趣的文章</h2><p><a href="http://blog.csdn.net/hzzhoushaoyu/article/details/52717220" rel="external nofollow noopener noreferrer" target="_blank">Web应用架构演进及系统性能、稳定性所需要解决的问题</a></p><p><a href="http://blog.csdn.net/hzzhoushaoyu/article/details/43273099" rel="external nofollow noopener noreferrer" target="_blank">dubbo学习过程、使用经验分享及实现原理简单介绍</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;http://www.quartz.ren&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;个人博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.kancloud.cn/thinkphp/docker_practice/
      
    
    </summary>
    
      <category term="生活学习" scheme="http://wiki.quartz.ren/categories/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="生活学习" scheme="http://wiki.quartz.ren/tags/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>规则引擎入门</title>
    <link href="http://wiki.quartz.ren/wiki/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/Drools/001.%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%85%A5%E9%97%A8/"/>
    <id>http://wiki.quartz.ren/wiki/工具组件/Drools/001.规则引擎入门/</id>
    <published>2019-02-24T01:56:24.000Z</published>
    <updated>2019-03-17T03:27:32.979Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://docs.jboss.org/drools/release/7.18.0.Final/drools-docs/html_single/index.html" rel="external nofollow noopener noreferrer" target="_blank">Drools Documentation</a></p><h2 id="Drools"><a href="#Drools" class="headerlink" title="Drools"></a>Drools</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>业务决策自动化</p><p>任何一家组织或企业都面临着作出决定或决策性的问题，这些问题通常比较复杂，一般都需要算法分析大量决策相关的数据，例如当前一些热门的话题，如物联网、人工智能、认知计算都基于算法分析海量数据，产生有用信息的过程。Drools 作为一个开源的推理引擎，有 20 年历史，基于规则匹配算法非常适用与与这一场景。</p><p>用于业务规则管理，业务资源优化和复杂事件处理（CEP）。 构建一个全面的业务自动化平台</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><p><a href="http://ksoong.org/drools-examples/content/docs/intro.html" rel="external nofollow noopener noreferrer" target="_blank">见Documennt</a></p><p>复杂规则编写: 条件元素，比较运算符,两种dialect的比较</p><h3 id="CEP"><a href="#CEP" class="headerlink" title="CEP"></a>CEP</h3><p>复杂时间处理.</p><p>复杂时间是多事件的事件处理概念，目标是在事件集合（事件流，事件云）中识别用户定义的有意义事件，CEP采用诸如检测许多事件的复杂模式，事件关联和抽象以及事件层的流程。</p><h3 id="规则整合"><a href="#规则整合" class="headerlink" title="规则整合"></a>规则整合</h3><p>通过不同的方式来管理获取规则</p><h3 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h3><h3 id="LABS"><a href="#LABS" class="headerlink" title="LABS"></a>LABS</h3><p>本部分通过实验来验证 Drools 相关的理论及概念。</p><h2 id="业务规则的定义抽象"><a href="#业务规则的定义抽象" class="headerlink" title="业务规则的定义抽象."></a>业务规则的定义抽象.</h2><h2 id="多个规则的智行顺序和规则管理"><a href="#多个规则的智行顺序和规则管理" class="headerlink" title="多个规则的智行顺序和规则管理"></a>多个规则的智行顺序和规则管理</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://docs.jboss.org/drools/release/7.18.0.Final/drools-docs/html_single/index.html&quot; rel=&quot;external nofollow noopener noreferre
      
    
    </summary>
    
      <category term="工具组件" scheme="http://wiki.quartz.ren/categories/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Drools" scheme="http://wiki.quartz.ren/categories/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/Drools/"/>
    
    
      <category term="规则引擎" scheme="http://wiki.quartz.ren/tags/%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/"/>
    
  </entry>
  
  <entry>
    <title>TODOLIST</title>
    <link href="http://wiki.quartz.ren/wiki/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/TODOLIST/README/"/>
    <id>http://wiki.quartz.ren/wiki/生活学习/TODOLIST/README/</id>
    <published>2019-02-24T01:56:24.000Z</published>
    <updated>2019-02-24T10:06:57.254Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一周计划"><a href="#一周计划" class="headerlink" title="一周计划"></a>一周计划</h3><ul><li>一道算法题</li><li>一篇英语文章</li><li>一个技术小技巧</li><li>一个观点分享</li></ul><p>把握好机会，别人给你的机会。<br>要看懂一些事情。不要装作什么都不知道。</p><p>不要说一些没有用的话，还不如不说</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一周计划&quot;&gt;&lt;a href=&quot;#一周计划&quot; class=&quot;headerlink&quot; title=&quot;一周计划&quot;&gt;&lt;/a&gt;一周计划&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;一道算法题&lt;/li&gt;
&lt;li&gt;一篇英语文章&lt;/li&gt;
&lt;li&gt;一个技术小技巧&lt;/li&gt;
&lt;li&gt;一个观点分享&lt;/
      
    
    </summary>
    
      <category term="生活学习" scheme="http://wiki.quartz.ren/categories/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TODOLIST" scheme="http://wiki.quartz.ren/categories/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/TODOLIST/"/>
    
    
      <category term="todo" scheme="http://wiki.quartz.ren/tags/todo/"/>
    
  </entry>
  
  <entry>
    <title>201902</title>
    <link href="http://wiki.quartz.ren/wiki/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/TODOLIST/201902/"/>
    <id>http://wiki.quartz.ren/wiki/生活学习/TODOLIST/201902/</id>
    <published>2019-02-24T01:56:24.000Z</published>
    <updated>2019-02-24T10:06:33.273Z</updated>
    
    <content type="html"><![CDATA[<h3 id="20190224"><a href="#20190224" class="headerlink" title="20190224"></a>20190224</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;20190224&quot;&gt;&lt;a href=&quot;#20190224&quot; class=&quot;headerlink&quot; title=&quot;20190224&quot;&gt;&lt;/a&gt;20190224&lt;/h3&gt;
      
    
    </summary>
    
      <category term="生活学习" scheme="http://wiki.quartz.ren/categories/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TODOLIST" scheme="http://wiki.quartz.ren/categories/%E7%94%9F%E6%B4%BB%E5%AD%A6%E4%B9%A0/TODOLIST/"/>
    
    
      <category term="todo" scheme="http://wiki.quartz.ren/tags/todo/"/>
    
  </entry>
  
  <entry>
    <title>ubunut 挂载samba</title>
    <link href="http://wiki.quartz.ren/wiki/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/Linux/ubuntu%E6%8C%82%E8%BD%BDsamba/"/>
    <id>http://wiki.quartz.ren/wiki/软件工程/Linux/ubuntu挂载samba/</id>
    <published>2019-02-24T01:56:24.000Z</published>
    <updated>2019-02-24T01:32:55.844Z</updated>
    
    <content type="html"><![CDATA[<h3 id="ubunut-挂载smb"><a href="#ubunut-挂载smb" class="headerlink" title="ubunut 挂载smb"></a>ubunut 挂载smb</h3><p><a href="https://blog.csdn.net/agrapier/article/details/80896397" rel="external nofollow noopener noreferrer" target="_blank">ubuntu18.04挂载smb</a><br><a href="https://blog.csdn.net/lujun9972/article/details/46002905" rel="external nofollow noopener noreferrer" target="_blank">linux挂载samba文件系统的方法</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install cifs-utils</span><br><span class="line">sudo mount -t cifs -o username=xxx,password=xxx //$&#123;ip&#125;/deploy/download /mnt/download</span><br></pre></td></tr></table></figure></p><p>sslocal -s 108.160.129.222 -p 25002 -k ‘2018vultr@lgqsb’ -l 1080 -t 600 -m aes-256-cfb -d $1 –pid-file /tmp/vpn-agent.pid –log-file /tmp/vpn-agent.log</p><p>export GIO_EXTRA_MODULES=/usr/lib/x86_64-linux-gnu/gio/modules/</p><p>if [ $1 == ‘stop’ ];then<br>        gsettings set org.gnome.system.proxy mode ‘none’<br>        echo ‘stop 1232.’<br>else<br>        gsettings set org.gnome.system.proxy.http host ‘127.0.0.1’<br>        gsettings set org.gnome.system.proxy.http port 1080<br>        gsettings set org.gnome.system.proxy mode ‘manual’<br>        echo ‘start 22222.’<br>fi</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;ubunut-挂载smb&quot;&gt;&lt;a href=&quot;#ubunut-挂载smb&quot; class=&quot;headerlink&quot; title=&quot;ubunut 挂载smb&quot;&gt;&lt;/a&gt;ubunut 挂载smb&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net
      
    
    </summary>
    
      <category term="软件工程" scheme="http://wiki.quartz.ren/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="Linux" scheme="http://wiki.quartz.ren/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/Linux/"/>
    
    
      <category term="linux" scheme="http://wiki.quartz.ren/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://wiki.quartz.ren/wiki/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E9%97%AE%E9%A2%98/%E5%85%B3%E4%BA%8E%E9%9D%9E%E6%8A%80%E6%9C%AF%E7%B1%BB%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98/"/>
    <id>http://wiki.quartz.ren/wiki/软件工程/问题/关于非技术类的几个问题/</id>
    <published>2019-02-23T13:37:58.002Z</published>
    <updated>2019-02-23T13:37:58.002Z</updated>
    
    <content type="html"><![CDATA[<ul><li>创业的流程</li><li><p>别人的一些经历,经验,需要学习的地方,思想</p></li><li><p>有关管理,交流的问题,人的管理.</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;创业的流程&lt;/li&gt;
&lt;li&gt;&lt;p&gt;别人的一些经历,经验,需要学习的地方,思想&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;有关管理,交流的问题,人的管理.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      
    
    </summary>
    
      <category term="软件工程" scheme="http://wiki.quartz.ren/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
      <category term="问题" scheme="http://wiki.quartz.ren/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E9%97%AE%E9%A2%98/"/>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://wiki.quartz.ren/wiki/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/DataStore/Elasticsearch/ES%E6%9D%83%E9%99%90%E8%AE%BE%E7%BD%AE/"/>
    <id>http://wiki.quartz.ren/wiki/数据处理/DataStore/Elasticsearch/ES权限设置/</id>
    <published>2019-02-23T13:37:57.987Z</published>
    <updated>2019-02-23T13:37:57.987Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/zou79189747/article/details/81164576" rel="external nofollow noopener noreferrer" target="_blank">参考</a></p><ul><li>开启权限</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H &quot;Content-Type:application/json&quot; -XPOST  http://yun.quartz.ren:9200/_xpack/license/start_trial?acknowledge=true</span><br></pre></td></tr></table></figure><ul><li>修改es的配置</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">添加</span><br><span class="line">xpack.security.enabled: true</span><br></pre></td></tr></table></figure><ul><li>设置用户名和密码<a href="https://www.cnblogs.com/cjsblog/p/9501858.html" rel="external nofollow noopener noreferrer" target="_blank">详见</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-setup-passwords interactive</span><br></pre></td></tr></table></figure><blockquote><p>重要: 在Kibana中配置Security</p></blockquote><ul><li>添加用户,角色等操作.</li></ul><p><a href="https://blog.csdn.net/xiaoyu_BD/article/details/81698882" rel="external nofollow noopener noreferrer" target="_blank">6.3版本x-pack破解</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/zou79189747/article/details/81164576&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;参考&lt;/a&gt;&lt;/
      
    
    </summary>
    
      <category term="数据处理" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="DataStore" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/DataStore/"/>
    
      <category term="Elasticsearch" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/DataStore/Elasticsearch/"/>
    
    
  </entry>
  
  <entry>
    <title>常用操作命令与问题记录</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/4.%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E4%B8%8E%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    <id>http://wiki.quartz.ren/wiki/数据处理/组件安装配置/Hadoop组件安装/4.常用操作与问题记录/</id>
    <published>2019-02-16T04:56:24.000Z</published>
    <updated>2019-02-24T02:21:51.913Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>启动hadoop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></li><li><p>停止hadoop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>启动或停止所有，即：HDFS和Yarn</p></blockquote><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="一、dfs的端口9000不通"><a href="#一、dfs的端口9000不通" class="headerlink" title="一、dfs的端口9000不通"></a>一、dfs的端口9000不通</h3><p>原因：忘记格式化hdfs。</p><p>启动顺序</p><ul><li>1.启动hdfs</li><li>2.启动yarn</li><li>3.启动hbase</li></ul><h3 id="二、查看hbase在hdfs中目录时"><a href="#二、查看hbase在hdfs中目录时" class="headerlink" title="二、查看hbase在hdfs中目录时"></a>二、查看hbase在hdfs中目录时</h3><p>使用hadoop fs -ls /hbase查看hbase目录，出现以下信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">17/10/28 22:25:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br></pre></td></tr></table></figure><ul><li>hbase 可以配置使用本地文件系统（一般单击模式），也可以使用hdfs（伪集群或集群模式）</li><li>hbase 可以配置使用自己安装的zk，也可以使用自带的zk。</li></ul><p>hadoop的name、data文件夹下存放什么？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;p&gt;启动hadoop&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line
      
    
    </summary>
    
      <category term="数据处理" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="组件安装配置" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Hadoop组件安装" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="hadoop" scheme="http://wiki.quartz.ren/tags/hadoop/"/>
    
      <category term="hbase" scheme="http://wiki.quartz.ren/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>HBase伪集群模式安装</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/3.HBase%E4%BC%AA%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
    <id>http://wiki.quartz.ren/wiki/数据处理/组件安装配置/Hadoop组件安装/3.HBase伪集群模式安装/</id>
    <published>2019-02-16T04:56:24.000Z</published>
    <updated>2019-02-24T02:20:30.498Z</updated>
    
    <content type="html"><![CDATA[<p>同Hadoop安装，到<br><a href="http://archive.cloudera.com/cdh5/cdh/5/" rel="external nofollow noopener noreferrer" target="_blank">CDH版下载地址</a>下载hbase。选择 hbase-1.0.0-cdh5.4.0.tar.gz</p><blockquote><p>hbase伪分布式模式是基于hdfs环境的</p></blockquote><p>因此，在安装hadoop的前提下，我们配置Hbase的伪分布式模式如下：</p><ul><li>1.下载并解压</li><li>2.配置环境变量（可选）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line">#添加</span><br><span class="line">export  PATH=$PATH:/opt/app/skyeye/hbase-1.0.0-cdh5.4.0/bin</span><br><span class="line">. ~/.bashrc</span><br><span class="line">#验证</span><br><span class="line">hbase version</span><br></pre></td></tr></table></figure><h3 id="伪集群模式配置"><a href="#伪集群模式配置" class="headerlink" title="伪集群模式配置"></a>伪集群模式配置</h3><ul><li>1.配置 conf/hbase-env.sh<br>将JAVA_HOME变量设置为本机jdk路径。如下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/tools/jdk1.8.0_131  #配置本机的java安装根目录</span><br><span class="line">export HBASE_MANAGES_ZK=true       #配置使用hbase自带的zookeeper，不使用自己搭建的zookeeper</span><br></pre></td></tr></table></figure><p>如果使用 export HBASE_MANAGES_ZK=true， 即配置不使用hbase自带的zookeeper，使用自己搭建的zookeeper</p><blockquote><p>hbase可以使用自定义zookeeper管理，也可以使用自带的zookeeper。</p></blockquote><ul><li>2.配置conf/hbase-site.xml<br>修改hbase.rootdir,将其指向hdfs，并指定Hbase在HDFS上的存储路径。<br>将hbase.cluster.distributed设置为true。<br>添加zk的节点地址。如下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"> &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"> &lt;!--以下信息只有在使用自己搭建的zk时添加--&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">     &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">     &lt;value&gt;cdhnode1,cdhnode2,cdhnode3&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">    &lt;!--默认为/tmp/目录下--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/opt/app/skyeye/data/hbasetmp/&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><ul><li>3.启动HBase</li></ul><p>完成上述操作之后，启动HBase，需要先启动Hadoop。</p><p>启动及检查：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">zbm@node3:~$ start-all.sh </span><br><span class="line"></span><br><span class="line">zbm@node3:~$ jps</span><br><span class="line">9250 ResourceManager</span><br><span class="line">9683 Jps</span><br><span class="line">9365 NodeManager</span><br><span class="line">9110 SecondaryNameNode</span><br><span class="line">8935 DataNode</span><br><span class="line">8795 NameNode</span><br></pre></td></tr></table></figure><p>上述则Hadoop启动成功。</p><blockquote><p>当前版本。使用start-all.sh启动hadoop时会提示以下信息，所以建议分别启动hdfs和yarn。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh</span><br></pre></td></tr></table></figure><p>之后启动HBase，启动及检查</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">start-hbase.sh          # 启动Hbase</span><br><span class="line"></span><br><span class="line">zbm@node3:~$ jps        # 检查</span><br><span class="line">3728 Jps</span><br><span class="line">3123 HRegionServer</span><br><span class="line">2407 NodeManager</span><br><span class="line">1961 DataNode</span><br><span class="line">2298 ResourceManager</span><br><span class="line">3004 HMaster</span><br><span class="line">1852 NameNode</span><br><span class="line">2158 SecondaryNameNode</span><br><span class="line">2943 HQuorumPeer</span><br></pre></td></tr></table></figure><p>以上几个进程说明Hbase启动成功。</p><ul><li>4.Hbase操作    </li></ul><p>可以进入shell模式，通过命令行操作查看hbase数据库信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hbase shell    #进入shell模式</span><br><span class="line">list    # 查看当前数据库所有表信息</span><br><span class="line">describe &apos;member&apos;    # 查看表结构</span><br><span class="line"># 创建一个member表，其拥有member_id,address,info三个列族</span><br><span class="line">create &apos;member&apos;,&apos;member_id&apos;,&apos;address&apos;,&apos;info&apos;</span><br></pre></td></tr></table></figure><ul><li>5.查看HDFS的HBase数据库文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">zbm@node3:～$ hadoop fs -ls /hbase</span><br><span class="line">17/10/28 20:45:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 6 items</span><br><span class="line">drwxr-xr-x   - nova supergroup          0 2017-10-28 00:03 /hbase/.tmp</span><br><span class="line">drwxr-xr-x   - nova supergroup          0 2017-10-28 00:03 /hbase/WALs</span><br><span class="line">drwxr-xr-x   - nova supergroup          0 2017-10-28 00:03 /hbase/data</span><br><span class="line">-rw-r--r--   3 nova supergroup         42 2017-10-28 00:03 /hbase/hbase.id</span><br><span class="line">-rw-r--r--   3 nova supergroup          7 2017-10-28 00:03 /hbase/hbase.version</span><br><span class="line">drwxr-xr-x   - nova supergroup          0 2017-10-28 00:14 /hbase/oldWALs</span><br></pre></td></tr></table></figure><ul><li>6.停止HBase</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-hbase.sh    #停止Hbase</span><br></pre></td></tr></table></figure><p>问题：停止hbase时，HRegionServer进程不能停止。会导致下次启动hbase时出错。</p><p>原因:</p><h3 id="HBase的用户界面"><a href="#HBase的用户界面" class="headerlink" title="HBase的用户界面"></a>HBase的用户界面</h3><ul><li>yarn: <a href="http://192.168.1.20:8088/cluster" rel="external nofollow noopener noreferrer" target="_blank">http://192.168.1.20:8088/cluster</a></li><li><p>hdfs状态: <a href="http://192.168.1.20:50070/dfshealth.html#tab-overview" rel="external nofollow noopener noreferrer" target="_blank">http://192.168.1.20:50070/dfshealth.html#tab-overview</a></p></li><li><p>Master: <a href="http://192.168.1.20:60010/master.jsp" rel="external nofollow noopener noreferrer" target="_blank">http://192.168.1.20:60010/master.jsp</a></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;同Hadoop安装，到&lt;br&gt;&lt;a href=&quot;http://archive.cloudera.com/cdh5/cdh/5/&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;CDH版下载地址&lt;/a&gt;
      
    
    </summary>
    
      <category term="数据处理" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="组件安装配置" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Hadoop组件安装" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="hadoop" scheme="http://wiki.quartz.ren/tags/hadoop/"/>
    
      <category term="hbase" scheme="http://wiki.quartz.ren/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>伪集群模式安装</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/2.%E4%BC%AA%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E5%AE%89%E8%A3%85/"/>
    <id>http://wiki.quartz.ren/wiki/数据处理/组件安装配置/Hadoop组件安装/2.伪集群模式安装/</id>
    <published>2019-02-16T04:56:24.000Z</published>
    <updated>2019-02-24T02:19:04.336Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.liyang.io/108.html" rel="external nofollow noopener noreferrer" target="_blank">搭建hadoop-2.6.0-cdh5.4.7伪分布式</a></p><p><a href="http://archive.cloudera.com/cdh5/cdh/5/" rel="external nofollow noopener noreferrer" target="_blank">CDH版下载地址</a></p><p>先来看看什么是CDH，为什么选择CHD版的Hadoop。</p><h2 id="CDH"><a href="#CDH" class="headerlink" title="CDH"></a>CDH</h2><p>属于Hadoop的一个发行版。</p><p>Hadoop有以下发行版：</p><ul><li>Apache Hadoop</li><li>Cloudera’s Distribution Including Apache Hadoop（CDH）</li><li>Hortonworks Data Platform (HDP)</li><li>MapR</li><li>EMR</li></ul><p>CDH版有以下优点：</p><ul><li>版本划分清晰</li><li>版本更新速度快</li><li>支持Kerberos安全认证</li><li>文档清晰</li><li>支持多种安装方式（Cloudera Manager方式）</li></ul><h2 id="安装hadoop-2-6-0-cdh5-4-0"><a href="#安装hadoop-2-6-0-cdh5-4-0" class="headerlink" title="安装hadoop-2.6.0-cdh5.4.0"></a>安装hadoop-2.6.0-cdh5.4.0</h2><p>首先到指定网站下载安装包<br><a href="http://archive.cloudera.com/cdh5/cdh/5/" rel="external nofollow noopener noreferrer" target="_blank">CDH版下载地址</a></p><p>解压下载的安装包</p><h3 id="配置伪集群"><a href="#配置伪集群" class="headerlink" title="配置伪集群"></a>配置伪集群</h3><ul><li>1、进入 hadoop-2.6.0-cdh5.4.0/etc/hadoop</li><li><p>2、编辑 hadoop-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi hadoop-env.sh</span><br></pre></td></tr></table></figure></li><li><p>3、修改JAVA_HOME的配置为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/tools/jdk1.8.0_131</span><br></pre></td></tr></table></figure></li><li><p>4、编辑core-site.xml,添加如下配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://node2:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li></ul><p>node2说明，如果没有配置hosts，请将node2换成IP地址:wp保存并退出。</p><ul><li>5、编辑hdfs-site.xml,添加如下配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!--开启web hdfs--&gt;</span><br><span class="line">        &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/opt/cdh/hadoop/name&lt;/value&gt;</span><br><span class="line">        &lt;description&gt; namenode 存放name table(fsimage)本地目录（需要修改）&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.edits.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;$&#123;dfs.namenode.name.dir&#125;&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;namenode存放 transactionfile(edits)本地目录（请自行修改）&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;/opt/cdh/hadoop/data&lt;/value&gt;</span><br><span class="line">       &lt;description&gt;datanode存放block本地目录（请自行修改）&lt;/description&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li></ul><p>以上配置完成，还需要创建文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p cdh/hadoop/name</span><br><span class="line">mkdir  cdh/hadoop/data</span><br></pre></td></tr></table></figure><ul><li><p>6、配置mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">之后加入以下配置</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li><li><p>7、编辑yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li></ul><p>到此，所有配置都已完成。</p><h3 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化HDFS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure><p>看到如下信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">************************************************************/</span><br><span class="line">15/09/22 14:59:46 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]</span><br><span class="line">15/09/22 14:59:46 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">15/09/22 14:59:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">15/09/22 14:59:49 WARN common.Util: Path /opt/cdh/hadoop/name should be specified as a URI in configuration files. Please update hdfs configuration.</span><br><span class="line">15/09/22 14:59:49 WARN common.Util: Path /opt/cdh/hadoop/name should be specified as a URI in configuration files. Please update hdfs configuration.</span><br><span class="line">Formatting using clusterid: CID-41ea6672-a32e-4b16-b704-962381ed409a</span><br><span class="line">15/09/22 14:59:49 INFO namenode.FSNamesystem: No KeyProvider found.</span><br><span class="line">15/09/22 14:59:49 INFO namenode.FSNamesystem: fsLock is fair:true</span><br><span class="line">15/09/22 14:59:49 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000</span><br><span class="line">15/09/22 14:59:49 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true</span><br><span class="line">15/09/22 14:59:49 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000</span><br><span class="line">15/09/22 14:59:49 INFO blockmanagement.BlockManager: The block deletion will start around 2015 九月 22 14:59:49</span><br><span class="line">15/09/22 14:59:49 INFO util.GSet: Computing capacity for map BlocksMap</span><br><span class="line">15/09/22 14:59:49 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/09/22 14:59:49 INFO util.GSet: 2.0% max memory 966.7 MB = 19.3 MB</span><br><span class="line">15/09/22 14:59:49 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: defaultReplication         = 1</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: encryptDataTransfer        = false</span><br><span class="line">15/09/22 14:59:50 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: isPermissionEnabled = true</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: HA Enabled: false</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: Append Enabled: true</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: Computing capacity for map INodeMap</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: 1.0% max memory 966.7 MB = 9.7 MB</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class="line">15/09/22 14:59:50 INFO namenode.NameNode: Caching file names occuring more than 10 times</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: Computing capacity for map cachedBlocks</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: 0.25% max memory 966.7 MB = 2.4 MB</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: capacity      = 2^18 = 262144 entries</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000</span><br><span class="line">15/09/22 14:59:50 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10</span><br><span class="line">15/09/22 14:59:50 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10</span><br><span class="line">15/09/22 14:59:50 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">15/09/22 14:59:50 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: Computing capacity for map NameNodeRetryCache</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB</span><br><span class="line">15/09/22 14:59:50 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class="line">15/09/22 14:59:50 INFO namenode.NNConf: ACLs enabled? false</span><br><span class="line">15/09/22 14:59:50 INFO namenode.NNConf: XAttrs enabled? true</span><br><span class="line">15/09/22 14:59:50 INFO namenode.NNConf: Maximum size of an xattr: 16384</span><br><span class="line">15/09/22 14:59:51 INFO namenode.FSImage: Allocated new BlockPoolId: BP-314159059-192.168.1.3-1442905191056</span><br><span class="line">15/09/22 14:59:51 INFO common.Storage: Storage directory /opt/cdh/hadoop/name has been successfully formatted.</span><br><span class="line">15/09/22 14:59:51 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">15/09/22 14:59:51 INFO util.ExitUtil: Exiting with status 0</span><br><span class="line">15/09/22 14:59:51 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at node2/192.168.1.3</span><br><span class="line">************************************************************/</span><br></pre></td></tr></table></figure><p>如果不报错，则格式化成功。</p><p>然后分别启动HDFS和Yarn：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><p>启动过程没有错误则启动成功。</p><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><ul><li>使用jps可以查看相关进程</li></ul><p>显示如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">nova@ubuntu208:~$ jps</span><br><span class="line">7667 Jps</span><br><span class="line">28532 DataNode</span><br><span class="line">28742 SecondaryNameNode</span><br><span class="line">29319 NodeManager</span><br><span class="line">28376 NameNode</span><br><span class="line">29018 ResourceManager</span><br></pre></td></tr></table></figure><ul><li>管理地址</li></ul><p>yarn: <a href="http://192.168.1.34:8088/cluster" rel="external nofollow noopener noreferrer" target="_blank">http://192.168.1.34:8088/cluster</a></p><p>hdfs状态: <a href="http://192.168.1.34:50070/dfshealth.html#tab-overview" rel="external nofollow noopener noreferrer" target="_blank">http://192.168.1.34:50070/dfshealth.html#tab-overview</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://blog.liyang.io/108.html&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;搭建hadoop-2.6.0-cdh5.4.7伪分布式&lt;/a&gt;&lt;/p&gt;
      
    
    </summary>
    
      <category term="数据处理" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="组件安装配置" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Hadoop组件安装" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="hadoop" scheme="http://wiki.quartz.ren/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Reactive</title>
    <link href="http://wiki.quartz.ren/wiki/%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
    <id>http://wiki.quartz.ren/wiki/编程相关/响应式编程/</id>
    <published>2019-01-08T03:55:57.000Z</published>
    <updated>2019-02-26T15:44:10.141Z</updated>
    
    <content type="html"><![CDATA[<h2 id="响应式编程"><a href="#响应式编程" class="headerlink" title="响应式编程"></a>响应式编程</h2><p>基于事件驱动(事件模式，或者订阅者模式)，类似于Netty异步事件编程模型．</p><p>对不同的事件做不同的处理．所有信息都通过一个编程模型处理．</p><h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><p>传统模型相比</p><ol><li>JavaWeb开发，基于Servlet. Servlet3.0之前 线程阻塞模型，只有当业务处理完成并返回后时结束Servlet线程．</li><li>3.0规范新特性，支持异步处理－Servlet线程将耗时操作委派给另一个线程完成.在不生成响应的情况下返回至容器．（问题）</li></ol><h3 id="Guava的EventBus实现"><a href="#Guava的EventBus实现" class="headerlink" title="Guava的EventBus实现"></a>Guava的EventBus实现</h3><p>订阅者模式，观察者模式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EventBusDemo</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Subscribe</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessageByMail</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"邮件发送一条信息："</span> + message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Subscribe</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessageByPhone</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"短信发送一条信息:"</span> + message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        EventBus eventBus = <span class="keyword">new</span> EventBus();</span><br><span class="line">        eventBus.register(<span class="keyword">new</span> EventBusDemo());</span><br><span class="line">        eventBus.post(<span class="string">"hi, boys"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Mono和Flux常用API"><a href="#Mono和Flux常用API" class="headerlink" title="Mono和Flux常用API"></a>Mono和Flux常用API</h3><p>都是数据反应式编程的核心组件．</p><p>Reactor是JVM的完全非阻塞响应式编程基础，具有高效的需求管理（以管理”背压”的形式）<br>它直接与Java 8功能的API，特别是整合CompletableFuture，Stream和 Duration</p><p>Flux 相当于一个 RxJava Observable 观察者</p><h3 id="WebFlux"><a href="#WebFlux" class="headerlink" title="WebFlux"></a>WebFlux</h3><p>Spring WebFlux是随Spring 5推出的响应式Web框架。</p><p><a href="https://blog.csdn.net/get_set/article/details/79480233" rel="external nofollow noopener noreferrer" target="_blank">Spring WebFlux快速上手——响应式Spring的道法术器</a></p><p>微服务,部署包大小,应用占用内存大小.</p><h3 id="Rsocket"><a href="#Rsocket" class="headerlink" title="Rsocket"></a>Rsocket</h3><p>用于响应式应用程序的新网络协议(应用层协议)．</p><p>提供Java，JavaScript，C ++和Kotlin等实现</p><p>它是一种基于Reactive Streams背压的双向，多路复用，基于消息的二进制协议</p><p>语言无关.</p><h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>该协议专门设计用于与Reactive风格应用配合使用，这些应用程序基本上是非阻塞的，并且通常（但不总是）与异步行为配对</p><p>所谓Reactive背压: 即发布者无法向订户发送数据直到该订户已经准备就绪的想法，这是与“异步”的关键区别。（服务端主动）</p><p>问题: 很多个客户端对于同一个消息，准备好的时间层次不一，服务端怎么控制这个(这个消息需要一直保存着吗，什么时候清理)．</p><blockquote><p>反应式编程(响应式reactive)是 Java 中高效应用的下一个前沿。但有两个主要障碍 -数据访问和网络。RSocket旨在解决后一个问题，而R2DBC旨在解决前者问题。</p></blockquote><p><a href="https://www.codercto.com/a/29868.html" rel="external nofollow noopener noreferrer" target="_blank">响应式应用新协议RSocket</a></p><p>iPhone和Andriod手机，与后端服务交互，提供数据统计，所有这些互动模型，http并不是为此设计．</p><blockquote><p>http. 超文本传输协议,用于从WWW服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少.</p></blockquote><blockquote><p>rest. 基于HTTP的REST服务. restTemplate. 获取http资源, 通过指定的一些格式(json等)．</p></blockquote><ul><li>数据统计收集</li><li>消息推送</li><li>异步响应</li></ul><h4 id="RSocket、-Envoy和-Istio"><a href="#RSocket、-Envoy和-Istio" class="headerlink" title="RSocket、. Envoy和. Istio"></a>RSocket、. Envoy和. Istio</h4><p><a href="https://yq.aliyun.com/articles/683037?utm_content=g_1000035441" rel="external nofollow noopener noreferrer" target="_blank">从微服务治理的角度看RSocket、. Envoy和. Istio</a></p><p>重点是把反应流的实现，提升到应用层上来。<br>其实在底层的协议中，就有反应流的实现，tcp的滑动窗口就是很好的例子。</p><p>很大一部分的线上故障是由于阻塞链接造成的.</p><p>简单的例子是如果所有的通讯都是反应式的，那就不用容断了.</p><h4 id="与http不同的四种交互模式-（重点）"><a href="#与http不同的四种交互模式-（重点）" class="headerlink" title="与http不同的四种交互模式 （重点）"></a>与http不同的四种交互模式 （重点）</h4><ul><li><p>Fire-and-Forget<br>优化请求/响应，在不需要响应时非常有用，例如非关键事件日志记录。</p></li><li><p>请求/响应<br>当您发送一个请求并收到一个响应时，就像HTTP一样。即使在这里，该协议也具有优于HTTP的优点，因为它是异步和多路复用的。</p></li><li><p>请求/流<br>类似于返回集合的请求/响应，集合被回送而不是查询直到完成，因此例如发送银行帐号，用实时的帐户事务流进行响应。</p></li><li><p>频道<br>允许任意交互模型的双向消息流。</p></li></ul><p>Unix网络编程模型中，底层操作系统的通道都是全双工的，同时支持读写操作．</p><p>多路复用的Selector不短的轮询注册在其上的Channel.如果某个Channel上面发生读或者写事件，这个Channel就处于就绪状态，会被Selector轮询出来．然后通过SelectionKey可以获取就绪的Channel的集合，进行后续的I/O操作.</p><p>TomcatNio　针对网络IO层面的异步－多路复用.(读写)</p><p>Rsocket是交互模式的异步.(或者说Rsocket的请求和响应与Http的请求和响应有什么区别，优点在那里.)</p><p>Http的异步通过callBack回调实现.(比如短信交互流程)</p><p>客户端使用http发送，短信平台和网关再到运营商都是长链接协议.短信平台受到同一链路上的送达之后．会callBack客户端.客户端收到后，处理回调．如果回调资源处理不当(处理不过来),会导致回调消息丢失．　(Rsocket回压场景)</p><p>这种http的异步是通过应用程序多次请求实现.再就是客户端层面控制异步. 将请求后的等待丢进线程池或者队列来存储 AsyncCall，然后去做其他的事情．</p><blockquote><p>将 AsycnCall 添加到队列中。将任务交给 Dispatcher 去执行。<br>比如　OKHTTP实现的异步请求．</p></blockquote><ul><li>使用线程池处理异步任务（这种开销太大，很少做）.真正的异步执行者 AsyncCall</li><li>使用队列.将 AsycnCall 添加到队列中。将任务交给 Dispatcher 去执行</li></ul><p>在使用 Dispatcher 会将 AsyncCall 交给指定的线程去执行，而 AsyncCall 是 NamedRunnable 的子类</p><p><a href="https://www.jianshu.com/p/3214ef86a52d" rel="external nofollow noopener noreferrer" target="_blank">OKHTTP异步和同步请求简单分析</a></p><p>Rsocket的异步，理解为没有收到响应，链接保持，但可以做其他事情，受到响应后再做处理.Rsocket天然支持?</p><p><a href="https://www.jianshu.com/p/76ff17bc6dea" rel="external nofollow noopener noreferrer" target="_blank">深度解读Tomcat中的NIO模型</a></p><p><a href="https://www.jdon.com/tags/24484" rel="external nofollow noopener noreferrer" target="_blank">异步编程：协作性多任务处理</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;响应式编程&quot;&gt;&lt;a href=&quot;#响应式编程&quot; class=&quot;headerlink&quot; title=&quot;响应式编程&quot;&gt;&lt;/a&gt;响应式编程&lt;/h2&gt;&lt;p&gt;基于事件驱动(事件模式，或者订阅者模式)，类似于Netty异步事件编程模型．&lt;/p&gt;
&lt;p&gt;对不同的事件做不同的处理
      
    
    </summary>
    
      <category term="编程相关" scheme="http://wiki.quartz.ren/categories/%E7%BC%96%E7%A8%8B%E7%9B%B8%E5%85%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>开发工具</title>
    <link href="http://wiki.quartz.ren/wiki/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/IDE/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    <id>http://wiki.quartz.ren/wiki/工具组件/IDE/开发工具/</id>
    <published>2019-01-08T03:55:57.000Z</published>
    <updated>2019-02-23T13:37:57.985Z</updated>
    
    <content type="html"><![CDATA[<h3 id="好用的开发工具"><a href="#好用的开发工具" class="headerlink" title="好用的开发工具"></a>好用的开发工具</h3><p><a href="https://dbeaver.io/download/" rel="external nofollow noopener noreferrer" target="_blank">dbeaver</a></p><p><a href="https://nosqlbooster.com/downloads" rel="external nofollow noopener noreferrer" target="_blank">https://nosqlbooster.com/downloads</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;好用的开发工具&quot;&gt;&lt;a href=&quot;#好用的开发工具&quot; class=&quot;headerlink&quot; title=&quot;好用的开发工具&quot;&gt;&lt;/a&gt;好用的开发工具&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://dbeaver.io/download/&quot; rel=&quot;extern
      
    
    </summary>
    
      <category term="工具组件" scheme="http://wiki.quartz.ren/categories/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/"/>
    
      <category term="IDE" scheme="http://wiki.quartz.ren/categories/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/IDE/"/>
    
    
  </entry>
  
  <entry>
    <title>前端框架</title>
    <link href="http://wiki.quartz.ren/wiki/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/%E5%89%8D%E7%AB%AF%E6%96%B9%E6%A1%88/%E5%89%8D%E7%AB%AF%E6%A1%86%E6%9E%B6%E8%AE%B0%E5%BD%95/"/>
    <id>http://wiki.quartz.ren/wiki/工具组件/前端方案/前端框架记录/</id>
    <published>2019-01-08T03:55:57.000Z</published>
    <updated>2019-02-24T02:17:02.307Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://antd-admin.zuiidea.com/zh/dashboard" rel="external nofollow noopener noreferrer" target="_blank">https://antd-admin.zuiidea.com/zh/dashboard</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://antd-admin.zuiidea.com/zh/dashboard&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://antd-admin.zuii
      
    
    </summary>
    
      <category term="工具组件" scheme="http://wiki.quartz.ren/categories/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/"/>
    
      <category term="前端方案" scheme="http://wiki.quartz.ren/categories/%E5%B7%A5%E5%85%B7%E7%BB%84%E4%BB%B6/%E5%89%8D%E7%AB%AF%E6%96%B9%E6%A1%88/"/>
    
    
  </entry>
  
  <entry>
    <title>ssh免密登录</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/1.%E9%85%8D%E7%BD%AEssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/"/>
    <id>http://wiki.quartz.ren/wiki/数据处理/组件安装配置/Hadoop组件安装/1.配置ssh免密登录/</id>
    <published>2019-01-08T03:55:57.000Z</published>
    <updated>2019-02-24T02:17:40.707Z</updated>
    
    <content type="html"><![CDATA[<ul><li>1.首先查看电脑的SSH Keys是否存在</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -al ~/.ssh</span><br></pre></td></tr></table></figure><ul><li>2.存在以下文件则说明key已生成</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-rw------- 1 zbm zbm 1675 Oct 28 11:04 id_rsa</span><br><span class="line">-rw-r--r-- 1 zbm zbm  399 Oct 28 11:04 id_rsa.pub</span><br></pre></td></tr></table></figure><ul><li>3.否则生成key:</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure><ul><li>4.之后配置免密登陆：即将pub key put到远程服务器。输入密码，之后每次就可免密登陆。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id -i ~/.ssh/id_rsa.pub &lt;romte_ip&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;1.首先查看电脑的SSH Keys是否存在&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
      <category term="数据处理" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="组件安装配置" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
    
      <category term="Hadoop组件安装" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/Hadoop%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
    
  </entry>
  
  <entry>
    <title>ES介绍</title>
    <link href="http://wiki.quartz.ren/wiki/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/DataStore/Elasticsearch/ES%E4%BB%8B%E7%BB%8D/"/>
    <id>http://wiki.quartz.ren/wiki/数据处理/DataStore/Elasticsearch/ES介绍/</id>
    <published>2018-12-15T17:55:57.000Z</published>
    <updated>2019-02-23T13:37:57.986Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/geoloc.html" rel="external nofollow noopener noreferrer" target="_blank">Es介绍</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.elastic.co/guide/cn/elasticsearch/guide/current/geoloc.html&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_bl
      
    
    </summary>
    
      <category term="数据处理" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
      <category term="DataStore" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/DataStore/"/>
    
      <category term="Elasticsearch" scheme="http://wiki.quartz.ren/categories/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/DataStore/Elasticsearch/"/>
    
    
  </entry>
  
</feed>
